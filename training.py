# -*- coding: utf-8 -*-
"""DS assignment part 1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1fQ2wmBuM2Vc4WIBuHueXn4A_Ss_bcPb2
"""

import numpy as np # light package to do multiple array for 2 dimension
import pandas as pd # package to do dataframe
import matplotlib.pyplot as plt # do visualization
import seaborn as sns # to create histogram or other kind of graph

df = pd.read_csv ('DS assignment excel.csv') #import dataset

df

df.describe(include = 'all') # describing the table

df.shape

"""Checking if there is any null value in this table"""

df.isnull().sum() # idenfity if there is any missing value in this table

# find where is the null value in hp column
trace_missing_hp = pd.isnull(df['HP'])
df[trace_missing_hp]

"""Data Cleaning Process"""

# replace the null column with a median value
df.HP = df.HP.fillna(df.HP.median()) # it used numpy function to replace this value

df.isnull().sum()

"""Checking if there is any duplicated column"""

df[df.duplicated(keep = False)]

df.shape

df.head(10)

# to reset the numbering in the column number index
df = df.reset_index(drop = True)

df.head(10)

# this code is to make sure that the programming will not run from the start and run from the latest dataframe
# it need to create new table like restore point in pc
sf = df.copy()

sf.head()

"""Finding descriptive value"""

sf.describe(include = 'all')

"""Identify outlier"""

# plotting graph must use seaborn function
sns.distplot(sf['Price'])

"""Removing outlier using quantile method"""

#Removing Outliers using Quantile Method. Get the 99th percentile and keep the data below it
q = sf['Price'].quantile(0.99) #create one variable as q ---compute lline
sf = sf[sf['Price']<q] #process of selecting 99% quantile from data frame
sf.describe(include='all')

sns.distplot(sf['Price'])

from scipy.stats import chi2_contingency

# testing relationship
chi_rest = chi2_contingency(pd.crosstab(sf['Price'],sf['FuelType']))
print('For FuelType: chi2 statistic: {} and p-value: {} '.format(chi_rest[0],chi_rest[1]))

# testing the relationship between price and metcolor
chi_res1 = chi2_contingency(pd.crosstab(sf['Price'],sf['MetColor']))
print('For MetColor : chi2 statistic: {} and p-value: {}'.format(chi_res1[0],chi_res1[1]))

#Testing the relationship between price and brand
chi_res2 = chi2_contingency(pd.crosstab(sf['Price'],sf['KM']))
print('For KM: chi2 statistic : {} and p-value : {}'.format(chi_res2[0],chi_res2[1]))

# Testing the relationship between price and automatic
chi_res3 = chi2_contingency(pd.crosstab(sf['Price'],sf['Automatic']))
print('For Automatic: chi2 statistic : {} and p-value : {}'.format(chi_res3[0],chi_res3[1]))

"""Create new dataframe from selected column"""

sf.columns.values

da = sf[['Age','KM','HP','CC','Price']]
da.head()

da = sf[['Age','KM','HP','CC','Price']]
da.head(10)

"""Creating Dummy"""

# create dummy variable
dmy = pd.get_dummies(da,drop_first = True)
dmy.head(10)

# create legend for the tables
x = da.iloc[:,:-1]
y = da.iloc[:,-1]

"""Using StandardScaler"""

from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
scaler.fit(x)
x = scaler.transform(x)

from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(x,y,test_size = 0.2, random_state = 0)

x_test

"""Train data"""

import statsmodels.api as sm # the process of training
x_train = sm.add_constant(x_train) # add the input feature
reg_model = sm.OLS(y_train,x_train).fit()

"""Apply model with train data"""

x_test = sm.add_constant(x_test) # x_test is the test set
y_pred = reg_model.predict(x_test) # predicting the output
pt = pd.DataFrame({'Predicted Price':y_pred,'Actual Price':y_test}) # creating prediction dataframe
pt.head(10)

reg_model.summary() # to check the summary

plt.scatter(y_test,y_pred)
plt.xlabel('Actual Price', size = 15)
plt.ylabel('Predicted Price', size = 15)
plt.show()

gh = pt[['Predicted Price', 'Actual Price']]
gh.corr()

# add more columns
pt['Residual'] = pt['Actual Price'] - pt['Predicted Price']
pt.head(5)

import pickle
filename = 'car price test'
pickle.dump(reg_model, open(filename, 'wb')) # dump is used to save ur table

